{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2s4LktbpHy-"
   },
   "source": [
    "# Exercise 2. MNIST classification with Tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z3BwmU7ZpRBQ"
   },
   "source": [
    "### 1. 데이터 다운로드 (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2354,
     "status": "ok",
     "timestamp": 1568713581042,
     "user": {
      "displayName": "Donghoon Ham",
      "photoUrl": "",
      "userId": "02374592131762549817"
     },
     "user_tz": -540
    },
    "id": "9ONjky3OHp1y",
    "outputId": "a3fee3c0-1afb-45eb-e09b-dc643811429b"
   },
   "outputs": [],
   "source": [
    "## Loading MNIST dataset from keras\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def load_dataset(flatten=False):\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # normalize x\n",
    "    X_train = X_train.astype(float) / 255.\n",
    "    X_test = X_test.astype(float) / 255.\n",
    "\n",
    "    # we reserve the last 10000 training examples for validation\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    if flatten:\n",
    "        X_train = X_train.reshape([X_train.shape[0], -1])\n",
    "        X_val = X_val.reshape([X_val.shape[0], -1])\n",
    "        X_test = X_test.reshape([X_test.shape[0], -1])\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "## Printing dimensions\n",
    "print(X_train.shape, y_train.shape)\n",
    "## Visualizing the first digit\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDm37iAJqdzo"
   },
   "source": [
    "### 2. 데이터셋 Dimension 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1156,
     "status": "ok",
     "timestamp": 1568713584320,
     "user": {
      "displayName": "Donghoon Ham",
      "photoUrl": "",
      "userId": "02374592131762549817"
     },
     "user_tz": -540
    },
    "id": "P0wTdIeQpXuX",
    "outputId": "297d5c20-9919-4ce2-e710-9d42e91f95db"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1]*X_train.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1]*X_test.shape[2]))\n",
    "\n",
    "print('Train dimension:');print(X_train.shape)\n",
    "print('Test dimension:');print(X_test.shape)\n",
    "\n",
    "## Changing labels to one-hot encoded vector\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "print('Train labels dimension:');print(y_train.shape)\n",
    "print('Test labels dimension:');print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 964,
     "status": "ok",
     "timestamp": 1568713628834,
     "user": {
      "displayName": "Donghoon Ham",
      "photoUrl": "",
      "userId": "02374592131762549817"
     },
     "user_tz": -540
    },
    "id": "1W_pRab3q-F6",
    "outputId": "cf17ef3f-dfe8-41fd-d4fd-12ac0d5b59e4"
   },
   "outputs": [],
   "source": [
    "## Importing required libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "s = tf.InteractiveSession()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nsgLVLZt1WcI"
   },
   "source": [
    "### 3. 네트워크 파라미터 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Z9dSthWrEoo"
   },
   "outputs": [],
   "source": [
    "## Defining various initialization parameters for 784-512-256-10 MLP model\n",
    "num_classes = y_train.shape[1]\n",
    "num_features = X_train.shape[1]\n",
    "num_output = y_train.shape[1]\n",
    "num_layers_0 = 512\n",
    "num_layers_1 = 256\n",
    "starter_learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I3cSOyPD1kGJ"
   },
   "source": [
    "### 4-1. Input placeholder 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CrMRFFbgt_vp"
   },
   "outputs": [],
   "source": [
    "# Placeholders for the input data\n",
    "input_X = tf.placeholder('float32',shape =(None,num_features),name=\"input_X\")\n",
    "input_y = tf.placeholder('float32',shape = (None,num_classes),name='input_Y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vu0YHgBd1uvP"
   },
   "source": [
    "### 4-2. Weight & Bias Variable 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fD2vWHIBuHob"
   },
   "outputs": [],
   "source": [
    "## Weights initialized by random normal function with std_dev = 1/sqrt(number of input features)\n",
    "weights_0 = tf.Variable(tf.random_normal([num_features,num_layers_0], stddev=(1/tf.sqrt(float(num_features)))))\n",
    "bias_0 = tf.Variable(tf.random_normal([num_layers_0]))\n",
    "weights_1 = tf.Variable(tf.random_normal([num_layers_0,num_layers_1], stddev=(1/tf.sqrt(float(num_layers_0)))))\n",
    "bias_1 = tf.Variable(tf.random_normal([num_layers_1]))\n",
    "weights_2 = tf.Variable(tf.random_normal([num_layers_1,num_output], stddev=(1/tf.sqrt(float(num_layers_1)))))\n",
    "bias_2 = tf.Variable(tf.random_normal([num_output]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "37B78r8bLXNm"
   },
   "source": [
    "### 4-3. 네트워크 Forward Pass 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XQNlg19QuIdZ"
   },
   "outputs": [],
   "source": [
    "def forward_pass(input_x, input_y):\n",
    "\n",
    "  predicted_y = None\n",
    "  loss = None\n",
    "  \n",
    "  ###################\n",
    "    # TODO: input data로 부터 prediction과 loss를 return하는\n",
    "    #       네트워크의 forward pass를 작성하세요.\n",
    "    # ...\n",
    "\n",
    "  ###################\n",
    "  \n",
    "  return predicted_y, loss\n",
    "\n",
    "\n",
    "predicted_y, loss = forward_pass(input_X, input_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hLgQXE1J5eRV"
   },
   "source": [
    "### 4-3. Optimizer, Metric 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MoQ8I7RxuNA8"
   },
   "outputs": [],
   "source": [
    "## Variable learning rate\n",
    "learning_rate = tf.train.exponential_decay(starter_learning_rate, 0, 5, 0.85, staircase=True)\n",
    "## Adam optimzer for finding the right weight\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss,var_list=[weights_0,weights_1,weights_2,\n",
    "                                                                         bias_0,bias_1,bias_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-ONAD1IuOSl"
   },
   "outputs": [],
   "source": [
    "## Metrics definition\n",
    "correct_prediction = tf.equal(tf.argmax(y_train,1), tf.argmax(predicted_y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eveTOxko5Xvc"
   },
   "source": [
    "### 5. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 114132,
     "status": "ok",
     "timestamp": 1568713912480,
     "user": {
      "displayName": "Donghoon Ham",
      "photoUrl": "",
      "userId": "02374592131762549817"
     },
     "user_tz": -540
    },
    "id": "-BwRcNlOuPxM",
    "outputId": "cb98ad12-3547-4a67-bc5b-344b22737600"
   },
   "outputs": [],
   "source": [
    "## Training parameters\n",
    "batch_size = 128\n",
    "epochs=14\n",
    "dropout_prob = 0.6\n",
    "training_accuracy = []\n",
    "training_loss = []\n",
    "testing_accuracy = []\n",
    "s.run(tf.global_variables_initializer())\n",
    "for epoch in range(epochs):    \n",
    "    arr = np.arange(X_train.shape[0])\n",
    "    np.random.shuffle(arr)\n",
    "    for index in range(0,X_train.shape[0],batch_size):\n",
    "        s.run(optimizer, {input_X: X_train[arr[index:index+batch_size]],\n",
    "                          input_y: y_train[arr[index:index+batch_size]],\n",
    "                        keep_prob:dropout_prob})\n",
    "    training_accuracy.append(s.run(accuracy, feed_dict= {input_X:X_train, \n",
    "                                                         input_y: y_train,keep_prob:1}))\n",
    "    training_loss.append(s.run(loss, {input_X: X_train, \n",
    "                                      input_y: y_train,keep_prob:1}))\n",
    "    \n",
    "    ## Evaluation of model\n",
    "    testing_accuracy.append(accuracy_score(y_test.argmax(1), \n",
    "                            s.run(predicted_y, {input_X: X_test,keep_prob:1}).argmax(1)))\n",
    "    print(\"Epoch:{0}, Train loss: {1:.2f} Train acc: {2:.3f}, Test acc:{3:.3f}\".format(epoch,\n",
    "                                                                    training_loss[epoch],\n",
    "                                                                    training_accuracy[epoch],\n",
    "                                                                   testing_accuracy[epoch]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-W7YISxKxkb"
   },
   "source": [
    "### 6. 실험결과 plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1568701655324,
     "user": {
      "displayName": "Donghoon Ham",
      "photoUrl": "",
      "userId": "02374592131762549817"
     },
     "user_tz": -540
    },
    "id": "AusPmv2cuRU8",
    "outputId": "f01f1861-1222-49e9-cce2-f2f99617d427"
   },
   "outputs": [],
   "source": [
    "## Plotting chart of training and testing accuracy as a function of iterations\n",
    "iterations = list(range(epochs))\n",
    "plt.plot(iterations, training_accuracy, label='Train')\n",
    "plt.plot(iterations, testing_accuracy, label='Test')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('iterations')\n",
    "plt.show()\n",
    "print(\"Train Accuracy: {0:.2f}\".format(training_accuracy[-1]))\n",
    "print(\"Test Accuracy:{0:.2f}\".format(testing_accuracy[-1]))\n",
    "\n",
    "\n",
    "sample_size = 10\n",
    "\n",
    "samples = s.run(forward_pass(input_X, input_y)[0], \n",
    "                feed_dict={input_X: X_test[:sample_size], input_y: y_test[:sample_size]})\n",
    "prediction = samples.argmax(1)\n",
    "fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "for i in range(sample_size):\n",
    "\n",
    "    ax[0][i].set_axis_off()\n",
    "    ax[1][i].set_axis_off()\n",
    " \n",
    "    ax[0][i].imshow(np.reshape(X_test[i], (28, 28)))\n",
    "    \n",
    "plt.show()\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "exercise_2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
